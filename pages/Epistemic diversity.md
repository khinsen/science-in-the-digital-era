Epistemic diversity refers to the coexistence of multiple perspectives, research methodologies, theories, and models in a scientific discipline. Ideally, these different points of view participate in all debates, enriching and critiquing each other. From an evolutionary perspective, epistemic diversity is important to prevent scientific inquiry from getting stuck, with one point of view dominating a discipline and criticism of this point of view becoming impossible to get heard. History has shown that even the most successful scientific theories lose their status of "best known description" one day. Newtonian mechanics was considered an absolute Truth for two centuries, before relativity and then quantum mechanics revealed its limitations and degraded it to a practically very useful, but no longer universal reasoning framework about our universe.

Up to here, I expect that most scientifically educated readers would nod in agreement. And yet, epistemic diversity is threatened by two foundational ideas of the industrial age: automation and standardization. Both are important for scaling up production processes, increasing productivity and lowering costs. Since the 1950s, science has increasingly be considered a support for economic and thus industrial development, in addition to its traditional role of improving our understanding of the world. Perhaps the most visible symptom is the now common practice of evaluating scientists by productivity criteria. One way to be more productive is to adopt standard practices, and to apply one's acquired competences mechanically to as many specific situations as possible.

This quest for productivity has left its marks in the [Open Science](Open%20Science.md) movement, in particular in the [FAIR](FAIR.md) principles. Whereas Findability and Accessibility are uncritical, Interoperability and Reuse are about standardization and productivity. Making data interoperable with existing software and conventions often requires cutting it down, removing information that doesn't fit the imposed storage formats or protocols. Reusing data implies accepting the values and motivations behind their collection.

For software, reuse implies adopting a potentially large set of explicit and tacit hypotheses made by its developers, and living with its mostly unknown but inevitable bugs. Bugs and the difficulty of fixing them is usually cited as a reason *for* reusing software as much as possible, mutualizing the effort of maintenance among a larger community. That is fine if the goal is to eliminate as many bugs as possible. But in science, what really matters is to reduce the *impact* of bugs on results, and from that point of view, it's bugs going unnoticed that are the most serious problem. With diverse software and thus diverse bugs, the chance of them going unnoticed is smaller. Provided, of course, that the results from diversely buggy software packages are confronted, and the causes of any differences explored, which is not commonly done today. [Computational replicability](Computational%20replicability.md) matters.

In a world of finite resources, there is no obvious solution to the tension between doing the best possible job on one project or tool on one hand, and exploring multiple directions in the interest of epistemic diversity on the other hand. But we should at least remain aware of the tension.


Further reading:
  - [Open Science and Epistemic Diversity: Friends or Foes?](http://doi.org/10.1017/psa.2022.45) by [Sabina Leonelli](https://sociology.exeter.ac.uk/staff/leonelli/)
