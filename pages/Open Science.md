As the ongoing public debates about global challenges such as climate change or the Covid pandemic have shown, people are losing trust in science. In part this is due to societak changes that extend far beyond scientific practices: there is a general loss of trust in institutions, and in particular governments. Taking one more step back, there is a loss of trust in the hierarchical decision structures of Western societies, with its authorities that rely on the opinions of experts.

But there are also changes inside the scientific community that have contributed to the loss of trust, which is shared by many researchers themselves. The pressure towards productivity and the information technology revolution have encouraged and enabled scientists to do more research but at a lower level of rigor. The [reproducibility crisis](Reproducibility%20crisis.md) is a good illustration. The Open Science movement is a reaction to this development, aiming for more trustworthy processes at all levels with a focus on increasing transparency. This push towards transparency is in conflict with notions of intellectual property that have been put in place to ensure a competitive advantage both to individual scientists and teams and to institutions funding scientific research.

The first level of Open Science is Open Access: anyone should be able to consult the original publications of scientific findings, rather than having to rely on summaries provided by expert committees or journalists. Of course, few people can actually read and understand those publications. But the circle of people who can extract information from these articles is still much larger than the circle of people who could afford an exploration of the literature before Open Access, in particular in the less prosperous countries of our planet.

The second level is the publication of the datasets and software that underly most of today's scientific research. In the era of ubiquitous [computer-aided research](Computer-aided%20research.md), a published summary of a study and its outcome is simply no longer sufficient. Many details of the scientific methods are documented only in the code, and access to the data and code permits other scientists to study the same phenomena from a different perspective. Publication of data and code thus makes science more verifiable, and by enabling complementary work, it supports the construction of the web of interrelated findings that permits consensus formation.

The third level of Open Science is about laying open the decision procedures in scientific research. Which topics get explored, and by whom? Who decides which results get published? How does quality control actually work? Which biases affect any of these decisions? How do political and economic interests intervene? The ultimate goal is ensuring that scientific research, in particular when it is funded from public money, benefits society as a whole.

At this time, only the first level, Open Access, has made significant progress. Its necessity is accepted by all stakeholders, but the details of implementation remain a subject of debate. The main problem is the enormous power held by the traditional scientific publishers. In the digital era, their contribution to the publication process has become negligible, but they control the names of the well-respected traditional journals. These journal names are a key element in defining scientific reputation, a tendency that has become much stronger with the introduction of bibliometry into the evaluation processes of scientific institutions. The publishers are doing their best to monetize this control, by extracting hefty publication fees from authors of Open Access publications. There are clear signs that scientific institutions are willing to move away from bibliometry-based evaluation, though for now it is not clear by what it is going to be replaced.

The implementation of the second level is still in its early days. Non-publication of data and code is still the norm, and even when these crucial elements are made public, they are not included in the critical examination that a paper undergoes during peer review. For data, the [FAIR principles](https://www.go-fair.org/fair-principles/) have established criteria that are increasingly accepted, though not yet massively applied. For code, only a handful of journals perform elementary tests upon submission of a paper, such as checking for [computational reproducibility](Computational%20reproducibility.md).

So far, no effort at all is made to check if the computations conform to the scientific methods as described in the paper. There is not even any requirement for authors to provide readable code. Lack of incentives is one reason but probably not even the major one: the state of the art in scientific software makes it nearly impossible to write code that a human reader other than the authors can understand in sufficient detail. And if a reviewer cannot be expected to understand the code, there is no hope for the peer review process to inspect the code for correctness. My work on [digital scientific notations](Digital%20scientific%20notation.md) aims at addressing this issue.

Another open problem is the reviewing process itself. Today, individual reviewers are expected to comment on all aspects of a submitted study. This is not possible when dealing with publications that have a dozen authors from several disciplines and deploy millions of lines of code to analyze gigabytes of input data. Submissions must be reviewed by teams combining different specializations, one of which needs to be in scientific software engineering.

The third level is just beginning to be discussed. The keywords "diversity" and "inclusion" are appearing on the lists of criteria for composing committees, in an attempt to make these committees more representative of society at large. But this is not the same as making decision processes more transparent. Moreover, diversity and inclusion efforts so far only address the most egregious and outwardly visible misrepresentations, such as gender disparities. More subtle though numerically very important discriminations, such as the *de facto* exclusion from science of everyone who doesn't speak English, are not even discussed as possible objectives.
