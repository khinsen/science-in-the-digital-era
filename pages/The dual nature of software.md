One of the keys to understanding the causes of [computational irreproducibility](Computational%20reproducibility.md) is understanding the dual nature of software. Software has a human-facing side, which we call [source code](Source%20code.md), and a machine-facing side, which we call [binary code](Binary%20code.md). The latter is not a very adequate name, because everything in a computer is stored as binary data, including source code. But that's the jargon that has established itself. Binary code is what the computer's processor can directly execute. It's a sequence of instructions defined as bit patterns. It's not something you want to look at when dealing with software.

In the not-so-distant past, humans wrote binary code for software of moderate size. I have personally written binary code for the [Z80 processor](https://en.wikipedia.org/wiki/Zilog_Z80) in my [Colour Genie home computer](https://en.wikipedia.org/wiki/Colour_Genie) in the 1980s. That was the only option for programming that computer other than using the built-in [BASIC](https://en.wikipedia.org/wiki/BASIC) interpreter. It's fun to talk to a processor in its native language, but also very cumbersome. I quickly moved on to the Z80's [assembly language](https://en.wikipedia.org/wiki/Assembly_language), which is a textual language, meaning source code, in which each line maps to one processor instruction. I still wrote code at the level of processor registers and individual memory locations, but I wrote it as legible text. 

When you write source code, something or someone has to translate that source code to binary code before the software can be run. In order to write Z80 assembly code, I wrote a translation program, called an assembler. And since I didn't have an assembler when I wrote my assembler, I had to translate it to binary code myself. That can be done, but it's not fun. I have never done it again.

The main message is that running software written as source code requires some other piece of software that translates source code to binary code. Such software goes by different names: assemblers, compilers, interpreters, etc., depending on how it works exactly. If you don't write software yourself, you may well be unaware of this translation layer, as it is almost invisible. But it's there, and it matters.

One reason why translation software matters is that, like any other software, it usually has bugs. That's true even for old and widely used translation software, such as the [GNU compiler collection](https://gcc.gnu.org/). Check the paper "[Finding and understanding bugs in C compilers](https://doi.org/10.1145/1993498.1993532)" for some examples. Your source code can be perfectly correct, and yet produce wrong results because of a bug in your translation software. That's certainly much rarer than having a bug in your own source code, but it happens.

The second reason why translation software matters is that it's what ultimately defines the meaning (in technical terms, the [semantics](Semantics.md)) of the source code. A practically important case is [floating-point arithmetic](Floating-point%20arithmetic.md). Your processor very probably uses an instruction set that implements the [IEEE 754 standard](https://en.wikipedia.org/wiki/IEEE_754) for floating-point arithmetic. But none of the popular high-level languages for scientific computing (C, C++, Fortran, ...) lets you program in terms of IEEE 754 operations, which include details such as rounding modes that most people don't want to have to think about. It's the compiler that decides how exactly your nice mathematically-looking formulas are translated into IEEE 754 operations. And different compilers make different decisions (because language standards don't bother to deal with such details either). Most compilers let you influence their decisions via compile-time options, which however are not part of your source code. This is why floating-point operations are so often not reproducible. They are in fact perfectly reproducible if you use the same compiler with the same options, but few people even record this information along with their numerical results.

The third reason why translation software matters is that it can intentionally do nasty things, such as adding viruses or spy code to your software. That's not much of an issue in scientific computing, but a big source of worry for software that is widely deployed and/or relevant for someone's security. Ken Thompson's Turing Award speec, [Reflections on trusting trust](https://doi.org/10.1145/358198.358210), is the classical reference on this.

Unfortunately, most software today is distributed as binary code. Even [Open Source](Open%20Source.md) software is no exception. Open Source means that you can download the source code somewhere, but running the translation step is often so complicated that most people are unable to do it. Instead, they download binary code prepared by somebody else, usually via package managers such as Debian's [Advanced Package Tool](https://en.wikipedia.org/wiki/APT_(software)) or the multi-platform [Conda](https://en.wikipedia.org/wiki/Conda_(package_manager)). Container images, such as those you get from [Docker Hub](https://hub.docker.com/), contain binary code as well.

Using someone else's binary code means that you have to trust that someone to actually have compiled the source code that they claim to have compiled (because you cannot check that). And since you don't know which exact translation software was used, you cannot check if it has bugs, and you cannot reproduce the binary code if it ever disappears from the download server. That's by far the most frequent cause for [computational irreproducibility](Computational%20reproducibility.md) today.

The good news is that software distribution can be done better. [Guix](Guix.md) and [Nix](Nix.md) are two package managers that track the complete translation process, recursively (i.e. they even track how a compiler was compiled itself), and allow you to re-run it. You get all the source code, and the recipes that were applied for translating this source code to binary code. You can also get ready-make binary code (which is a lot more efficient), which however you can verify if you want to. Nice, isn't it?
