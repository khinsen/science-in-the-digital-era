[Open Science](Open%20Science.md) is very much in fashion today, but it remains a rather fuzzy concept. In addition to divergent opinions about what exactly should be made open, there are multiple degrees of openness. Most of the discussion around Open Science is about what I call "legally open": allowing everyone to access the outputs of research legally and at reasonable cost (which in the digital era means at no cost). Open access is all about being legally open, for example. The [Open Source](Open%20Source.md) movement in software started similarly, concentrating on licenses. What I will argue for in the following is that Open Science should be about making research outputs *effectively* open, by which I mean that research outputs are made *easily* accessible for as large an audience as reasonably possible.

To make the difference between the two concepts clearer, here is a useful analogy. Legally open means I am telling people: "All the results of my project are in the papers on my desk. Go have a look, the door is not locked." Effectively open is "Here is a summary of my project, with links to all the details you may need and references to textbooks you may have to read if you come from a different domain."

Effectively open corresponds to the tradition in scientific publishing. We don't submit photocopies of our lab notebooks to journals for reviewing and publication. We write articles *explaining* our work to readers, starting by describing the context and motivation for the work. And if an article is not sufficiently well written to be understandable, good journals will reject it, no matter how good or novel the underlying research work could possibly be.

There is a good reason for this tradition. Science is about increasing our knowledge of the world collectively. A contribution that nobody but the author can understand is not really a contribution. Moreover, science is built around an error correction protocol. To err is human, as is having biases that influence our reasoning. Such errors and biases are eliminated in the long run because individual contributions are critically examined by other scientists. They make errors and have biases as well, but, most probably, different ones. A particular strategy of critical examination, peer review of submissions to journals, has become the gold standard for quality control in science, even though there this is more of a historical accident than a conscious methodological choice.

If we want code and data to become research outputs of equal value to papers, we need to subject them to critical examination as well. It isn't obvious *how* best to do this, and I expect that experimentation with different techniques will be required. But it seems obvious to me that we have to introduce a requirement equivalent to the "well written" criterion for articles. It has to become the authors' responsibility to convince their colleagues of the quality of their code, their data, and the computational environments that they have chosen to base their work on. That means that code, data, and computational environments have to become effectively open. They must be amenable to critical examination, with reasonable effort, by independent experts, i.e. experts that were not involved in their creation.

The main obstacle to making code and computational environments effectively open is the [complexity of today's software stacks](Cheap%20complexity.md). Even an apparently perfectly documented data analysis presented as a [computational notebook](Computational%20notebook.md) is only superficially well documented. The code in the notebook typically makes use of many libraries, which in turn rely on an even larger number of lower-level libraries, with the total dependency graph easily containing hundreds of software packages. No reviewer can reasonably be expected to critically examine the whole software stack. On the other hand, most of the code in those hundreds of software packages is not relevant for the top-level data analysis. It may thus be possible to make the data analysis effectively open by organizing and packaging the code differently, or by providing inspection tools that guide its examination. This should become a research question in scientific [software engineering](Software%20engineering.md).

A completely different approach is to refactor scientific software with the goal of moving as much as possible into a small number of very widely usable packages. The generality of such packages would then justify significant efforts invested into developing and independently examining them. A typical researcher could then trust these packages on the basis of expert stamps of approval, rather than on personal examination. This approach is analogous to how we develop trust in industrial products, such as drugs or refrigerators, via technical norms, regulatory oversight, quality labels, and other sources of trust by delegation. The "industrial" core software would then be complemented by domain-specific and project-specific artefacts, which might be higher-level software layers or scientific models written in [digital scientific notations](Digital%20scientific%20notation.md).
